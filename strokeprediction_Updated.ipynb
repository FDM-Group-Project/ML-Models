{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "strokeprediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhWiYGZhDdnf"
      },
      "source": [
        "# **Import Libraries and import Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632647843844
        },
        "id": "nQTL-2qKsYh-"
      },
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "from azureml.core import Experiment\n",
        "from azureml.core import Model\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lhyTnnPmigF",
        "gather": {
          "logged": 1632648489589
        }
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.mlab as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQhY_gCrpYnq",
        "gather": {
          "logged": 1632647942715
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded =files.upload()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUln2t_5dA53"
      },
      "source": [
        "rawDataset =pd.read_csv('stroke.csv')\n",
        "rawDataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB_nQdrUyxqX",
        "gather": {
          "logged": 1632647951300
        }
      },
      "source": [
        "rawDataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ5hDMQ35rgO",
        "gather": {
          "logged": 1632647957737
        }
      },
      "source": [
        "# Drop the id column\n",
        "rawDataset.drop(['id'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXTcybNFbV8S"
      },
      "source": [
        "# **Checking Correlation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMCMN-cPa0rk",
        "gather": {
          "logged": 1632647963053
        }
      },
      "source": [
        "import seaborn as sns\n",
        "#Using Pearson Correlation\n",
        "plt.figure(figsize=(10,10))\n",
        "cor = rawDataset.corr()\n",
        "sns.heatmap(cor, annot=True, cmap=plt.cm.CMRmap_r)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY774QAad7Hu",
        "gather": {
          "logged": 1632647970546
        }
      },
      "source": [
        "#Checking the distributions of all columns\n",
        "figures = plt.figure(figsize = (20,25))\n",
        "axis = figures.gca()\n",
        "rawDataset.hist(ax = axis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5Cw4GOoqWJ2",
        "gather": {
          "logged": 1632647976222
        }
      },
      "source": [
        "sns.countplot(x='stroke',data=rawDataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMPQ3YB29F7V",
        "gather": {
          "logged": 1632647980092
        }
      },
      "source": [
        "rawDataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkTZpQVlzgLC"
      },
      "source": [
        "# **Checking Null values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZYP3lFp9Ly-",
        "gather": {
          "logged": 1632647985875
        }
      },
      "source": [
        "rawDataset.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFFSjKavzkGW"
      },
      "source": [
        "# **Replace Null Values With Mean Value**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sRtsMsB1d5y"
      },
      "source": [
        "# Create an Azure ML experiment in your workspace\n",
        "experiment = Experiment(workspace=ws, name=\"train-stroke-prediction\")\n",
        "run = experiment.start_logging()\n",
        "print(\"Starting experiment:\", experiment.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7kQreKg_3dt",
        "gather": {
          "logged": 1632647992050
        }
      },
      "source": [
        "#replacing bmi column missing values with mean\n",
        "mean_value_bmi=rawDataset['bmi'].mean()\n",
        "rawDataset['bmi']=rawDataset['bmi'].fillna(mean_value_bmi)\n",
        "rawDataset.isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxwLJ-cOwC0S"
      },
      "source": [
        "#replace yes and no with 1 and 0 in ever married column\n",
        "rawDataset['ever_married'] = rawDataset['ever_married'].map({'Yes': 1, 'No': 0})\n",
        "rawDataset['Residence_type'] = rawDataset['Residence_type'].map({'Urban': 1, 'Rural': 0})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkBpXmj66z9l"
      },
      "source": [
        "rawDataset = rawDataset.rename(columns={'Residence_type' : 'isUrban'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtpSw--01oec"
      },
      "source": [
        "#**Balancing the dataset using OverSampling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgwydtiA3igK",
        "gather": {
          "logged": 1632648295129
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "smotenc = SMOTENC(random_state=42, categorical_features=[0, 2, 3, 4, 5,6, 9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMsoONxiy5WR",
        "gather": {
          "logged": 1632648061220
        }
      },
      "source": [
        "#Spliiting data into testing and training\n",
        "Y = rawDataset['stroke']\n",
        "X = rawDataset.drop(['stroke'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFtcCzkv3kWt",
        "gather": {
          "logged": 1632648298444
        }
      },
      "source": [
        "X, Y=smotenc.fit_resample(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUIvBECJrDBp"
      },
      "source": [
        "Y_df = pd.DataFrame(Y, columns=['stroke'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPeBV8uqqsgS"
      },
      "source": [
        "X_df = pd.DataFrame(X, columns=rawDataset.columns.drop('stroke'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBei7Jdyt6Yh"
      },
      "source": [
        "ds = pd.concat([X_df, Y_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUt9GfTxuUEJ"
      },
      "source": [
        "sns.countplot(x='stroke',data=ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPS4BRTxhO0t"
      },
      "source": [
        "# **Onehot Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-06-6_66hVrQ",
        "gather": {
          "logged": 1632647997793
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc=OneHotEncoder()\n",
        "dataEncoded=enc.fit(ds[['gender','work_type','smoking_status']]).transform(ds[['gender','work_type','smoking_status']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uhlXFflh93a",
        "gather": {
          "logged": 1632648002931
        }
      },
      "source": [
        "temp=pd.DataFrame(dataEncoded.toarray(),columns=enc.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSF2PCk-iAOF",
        "gather": {
          "logged": 1632648006293
        }
      },
      "source": [
        "ds =pd.concat([temp,ds[['avg_glucose_level','isUrban','age','ever_married','hypertension','heart_disease','bmi', 'stroke']]], axis=1, join='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aMMHVpJxQiJ"
      },
      "source": [
        "ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JrrPmP7wLzM"
      },
      "source": [
        "# **Checking** **Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVwrKOY5wK-S",
        "gather": {
          "logged": 1632648030919
        }
      },
      "source": [
        "sns.boxplot(x=rawDataset['bmi'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ABoz4XG1O2p",
        "gather": {
          "logged": 1632648035049
        }
      },
      "source": [
        "sns.boxplot(x=rawDataset['avg_glucose_level'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8erNSW7wRDp",
        "gather": {
          "logged": 1632648045883
        }
      },
      "source": [
        "### Remove outliers based on the contamination value\n",
        "from sklearn.ensemble import IsolationForest\n",
        "rng = np.random.RandomState(42)\n",
        "iso = IsolationForest(max_samples='auto', contamination=float(0.1), n_estimators=100, random_state=rng)\n",
        "yhat = iso.fit_predict(ds.iloc[:, 0:-1])\n",
        "yhat.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9un_gB_wUEM",
        "gather": {
          "logged": 1632648052908
        }
      },
      "source": [
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "ds = ds.iloc[mask, :]\n",
        "ds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWxt0Jp_3oOT"
      },
      "source": [
        "# **Spliting the training and testing sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6fTB-mBu691"
      },
      "source": [
        "#Spliiting data into testing and training\n",
        "Y = ds['stroke']\n",
        "X = ds.drop(['stroke'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uRDBrLE3tVZ",
        "gather": {
          "logged": 1632648302217
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDUOBfnaVRNQ"
      },
      "source": [
        "# **Training dataset using  Different Models and Cheking Accuracy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwcrBKAgVmDa"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvR7zqcHvnfB"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC(kernel='rbf', C=1, gamma=0.001, random_state=1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_predict = model.predict(X_test)\n",
        "print(\"Accuracy:\" ,accuracy_score(y_test, y_predict))\n",
        "svm = accuracy_score(y_test, y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSsjSucQVqpU"
      },
      "source": [
        "# KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhEjt4zswFHl"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "Range_k = range(1,15)\n",
        "scores = {}\n",
        "scores_list = []\n",
        "for k in Range_k:\n",
        "   classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "   classifier.fit(X_train, y_train)\n",
        "   y_pred3 = classifier.predict(X_test)\n",
        "   scores[k] = metrics.accuracy_score(y_test,y_pred3)\n",
        "   scores_list.append(metrics.accuracy_score(y_test,y_pred3))\n",
        "\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred3))\n",
        "KNeighborsClassifier = metrics.accuracy_score(y_test, y_pred3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM2jq3vuhkLd"
      },
      "source": [
        "# Gaussian Naive Bayes model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NobBTZqWwJ_Z"
      },
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "gnb = GaussianNB()\n",
        "\n",
        "#Train the model using the training sets\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred2 = gnb.predict(X_test)\n",
        "\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred2))\n",
        "Gaussian_Naive_Bayes = metrics.accuracy_score(y_test, y_pred2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ3fdNH-hmLy"
      },
      "source": [
        "# RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C0LsaVewRuL"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 50)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred4 = classifier.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        " \n",
        "print(\"Accuracy:\",accuracy_score(y_test,y_pred4))\n",
        "RandomForestClassifier = accuracy_score(y_test,y_pred4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qrpH7wZXi5k"
      },
      "source": [
        "modeles = ['SVM','KNeighborsClassifier','Gaussian_Naive_Bayes','RandomForestClassifier']\n",
        "Accuracies = pd.DataFrame({\"Model\": modeles,\"Accuracy\": [svm,KNeighborsClassifier,Gaussian_Naive_Bayes,RandomForestClassifier]})\n",
        "Accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UL6xmyLlavh"
      },
      "source": [
        "# **Hyper** **Parameter** **Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8ELU4Y4lXio",
        "gather": {
          "logged": 1632648575331
        }
      },
      "source": [
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')\n",
        "#over=BorderlineSMOTE(sampling_strategy=0.3, k_neighbors=6)\n",
        "#under=RandomUnderSampler(sampling_strategy=0.4)\n",
        "\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [200]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators, \n",
        "               'min_samples_split': [1,2], \n",
        "               'min_samples_leaf': [1,2], \n",
        "               'max_features': ['sqrt','log2','auto'], \n",
        "               'max_depth': [10,20,30], \n",
        "               'bootstrap': [False,True]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgOSdJ3ml1js",
        "gather": {
          "logged": 1632648626989
        }
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "cv=RepeatedStratifiedKFold(n_splits=7, n_repeats=2, random_state=42)\n",
        "\n",
        "# Going to use RandomizedSearchCV because we have a lot of parameters and this way it will be more time efficient\n",
        "grid_search=RandomizedSearchCV(estimator=rf\n",
        "                               ,param_distributions=random_grid\n",
        "                               ,n_jobs=-1\n",
        "                               ,scoring='precision'\n",
        "                               ,cv=cv\n",
        "                               ,n_iter = 50\n",
        "                              )\n",
        "\n",
        "pipe=Pipeline([ ('model',grid_search)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as8N4isBpl3Y",
        "gather": {
          "logged": 1632649587825
        }
      },
      "source": [
        "pipe.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1tBaJf6Pf2e"
      },
      "source": [
        "print(\"Training Accuracy :\", pipe.score(X_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6uaIUC62hIs"
      },
      "source": [
        "# **Model Accuracy Stats**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632649902032
        },
        "id": "gqjzGJTssYjQ"
      },
      "source": [
        "# calculate accuracy\n",
        "y_hat = pipe.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "#run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = pipe.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "#run.log('AUC', np.float(auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6vN6JTCFiVv",
        "gather": {
          "logged": 1632644527982
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(\n",
        "    cm,\n",
        "    classes,\n",
        "    normalize=False,\n",
        "    title='Confusion matrix',\n",
        "    cmap=plt.cm.Blues,\n",
        "    ):\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = ('.2f' if normalize else 'd')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for (i, j) in itertools.product(range(cm.shape[0]),\n",
        "                                    range(cm.shape[1])):\n",
        "\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment='center', color=('white' if cm[i,\n",
        "                 j] > thresh else 'black'))\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_hat)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=['0', '1'],\n",
        "                      title='Confusion matrix')\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqFLEzEO3XDK"
      },
      "source": [
        "# **Model Deployment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632649914181
        },
        "id": "aTuwV8hTsYjS"
      },
      "source": [
        "# Save the trained model\n",
        "model_file = 'stroke_model.pkl'\n",
        "joblib.dump(value=pipe, filename=model_file)\n",
        "run.upload_file(name = model_file, path_or_stream = './' + model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632649930941
        },
        "id": "JqjOYoAIsYjU"
      },
      "source": [
        "# Complete the run\n",
        "run.complete()\n",
        "\n",
        "# Register the model\n",
        "run.register_model(model_path='stroke_model.pkl', model_name='stroke_model',\n",
        "                   tags={'Training context':'Inline Training'},\n",
        "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "print('Model trained and registered sucessfully')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632650051115
        },
        "id": "8boa2l-bsYjV"
      },
      "source": [
        "model = ws.models['stroke_model']\n",
        "print(model.name, 'version', model.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "ecS6PfoAsYjW"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the deployment files\n",
        "deployment_folder = './stoke_service'\n",
        "os.makedirs(deployment_folder, exist_ok=True)\n",
        "print(deployment_folder, 'folder created.')\n",
        "\n",
        "# Set path for scoring script\n",
        "script_file = 'score_stroke.py'\n",
        "script_path = os.path.join(deployment_folder,script_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "08XZsDu-sYjX"
      },
      "source": [
        "%%writefile $script_path\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Called when the service is loaded\n",
        "def init():\n",
        "    global model\n",
        "    # Get the path to the deployed model file and load it\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'stroke_model.pkl')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "# Called when a request is received\n",
        "def run(raw_data):\n",
        "    data_values = {'x0_Female' : 0,\n",
        " 'x0_Male':0,\n",
        " 'x0_Other':0,\n",
        " 'x1_Govt_job':0,\n",
        " 'x1_Never_worked':0,\n",
        " 'x1_Private':0,\n",
        " 'x1_Self-employed':0,\n",
        " 'x1_children':0,\n",
        " 'x2_Unknown':0,\n",
        " 'x2_formerly smoked':0,\n",
        " 'x2_never smoked':0,\n",
        " 'x2_smokes':0,\n",
        " 'avg_glucose_level':0, \n",
        " 'isUrban':0, \n",
        " 'age':0, \n",
        " 'ever_married' : 0, \n",
        " 'hypertension' :0,\n",
        "  'heart_disease' :0, \n",
        "  'bmi':0}\n",
        "    # Get the input data as a numpy array\n",
        "    data = json.loads(raw_data)['data']\n",
        "\n",
        "    if data['gender'] == \"Male\":\n",
        "        data_values['x0_Male'] = 1\n",
        "    elif data['gender'] == \"Female\":\n",
        "        data_values['x0_Female'] = 1\n",
        "    else:   \n",
        "        data_values['x0_Other'] = 1\n",
        "\n",
        "    if data['work_type'] == \"Government Job\":\n",
        "        data_values['x1_Govt_job'] = 1\n",
        "    elif data['work_type'] == \"Private Job\":\n",
        "        data_values['x1_Private'] = 1\n",
        "    elif data['work_type'] == \"Self Employed\":\n",
        "        data_values['x1_Self-employed'] = 1\n",
        "    elif data['work_type'] == \"Be with Children\":\n",
        "        data_values['x1_children'] = 1\n",
        "    else:\n",
        "        data_values['x1_Never_worked'] = 1\n",
        "\n",
        "    if data['smoking_status'] == \"Formerly Smoked\":\n",
        "        data_values['x2_formerly smoked'] = 1\n",
        "    elif data['smoking_status'] == \"Smokes\":\n",
        "        data_values['x2_smokes'] = 1\n",
        "    else:\n",
        "        data_values['x2_never smoked'] = 1\n",
        "\n",
        "    data_values['age'] = data['age']\n",
        "    data_values['avg_glucose_level'] = float(data['avg_glucose_level'])\n",
        "    data_values['hypertension'] = 1 if data['hypertension'] == \"Yes\" else 0\n",
        "    data_values['ever_married'] = 1 if data['ever_married'] == \"Yes\" else 0\n",
        "    data_values['heart_disease'] = 1 if data['heart_disease'] == \"Yes\" else 0\n",
        "    data_values['isUrban'] = 1 if data['isUrban'] == \"Yes\" else 0\n",
        "    data_values['bmi'] = float(data['weight']) / (float(data['height'])**2)\n",
        "    \n",
        "    a = list(data_values.values())  \n",
        "\n",
        "    # Get a prediction from the model\n",
        "    predictions = model.predict([a])\n",
        "    # Get the corresponding classname for each prediction (0 or 1)\n",
        "    classnames = ['not-stroke', 'stroke']\n",
        "    predicted_classes = []\n",
        "    for prediction in predictions:\n",
        "        predicted_classes.append(classnames[prediction])\n",
        "    # Return the predictions as JSON\n",
        "    return json.dumps(predicted_classes[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "VKqn_WzjsYjY"
      },
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "# Configure the scoring environment\n",
        "service_env = Environment(name='service-env')\n",
        "python_packages = ['scikit-learn', 'azureml-defaults', 'azure-ml-api-sdk','imblearn', 'seaborn', 'matplotlib', 'pandas', 'scipy']\n",
        "for package in python_packages:\n",
        "    service_env.python.conda_dependencies.add_pip_package(package)\n",
        "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
        "                                   entry_script=script_file,\n",
        "                                   environment=service_env)\n",
        "\n",
        "# Configure the web service container\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "# Deploy the model as a service\n",
        "print('Deploying model...')\n",
        "service_name = \"stroke-service\"\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
        "service.wait_for_deployment(True)\n",
        "print(service.state)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}